{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwTL_dQ1VjHo",
        "outputId": "2201fb9c-f82b-4abe-e42a-f8e56002ddf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJUQNK4b9jLE",
        "outputId": "81455d48-a402-4a48-8b40-4dbde090c80a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost scikit-learn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECumpLb_A3-1",
        "outputId": "74f8ecec-25e5-4808-a146-94751da5e04b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:31:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-mlogloss:1.35010\teval-mlogloss:1.35214\n",
            "[10]\ttrain-mlogloss:1.07435\teval-mlogloss:1.09673\n",
            "[20]\ttrain-mlogloss:0.90856\teval-mlogloss:0.94675\n",
            "[30]\ttrain-mlogloss:0.80498\teval-mlogloss:0.85581\n",
            "[40]\ttrain-mlogloss:0.73621\teval-mlogloss:0.79773\n",
            "[50]\ttrain-mlogloss:0.68801\teval-mlogloss:0.75751\n",
            "[60]\ttrain-mlogloss:0.65347\teval-mlogloss:0.72939\n",
            "[70]\ttrain-mlogloss:0.62945\teval-mlogloss:0.71087\n",
            "[80]\ttrain-mlogloss:0.60908\teval-mlogloss:0.69581\n",
            "[90]\ttrain-mlogloss:0.59361\teval-mlogloss:0.68474\n",
            "[100]\ttrain-mlogloss:0.58066\teval-mlogloss:0.67617\n",
            "[110]\ttrain-mlogloss:0.57033\teval-mlogloss:0.67016\n",
            "[120]\ttrain-mlogloss:0.56184\teval-mlogloss:0.66583\n",
            "[130]\ttrain-mlogloss:0.55414\teval-mlogloss:0.66247\n",
            "[140]\ttrain-mlogloss:0.54755\teval-mlogloss:0.65952\n",
            "[150]\ttrain-mlogloss:0.54154\teval-mlogloss:0.65745\n",
            "[160]\ttrain-mlogloss:0.53665\teval-mlogloss:0.65601\n",
            "[170]\ttrain-mlogloss:0.53204\teval-mlogloss:0.65503\n",
            "[180]\ttrain-mlogloss:0.52773\teval-mlogloss:0.65418\n",
            "[190]\ttrain-mlogloss:0.52379\teval-mlogloss:0.65356\n",
            "[200]\ttrain-mlogloss:0.52000\teval-mlogloss:0.65326\n",
            "[210]\ttrain-mlogloss:0.51656\teval-mlogloss:0.65299\n",
            "[220]\ttrain-mlogloss:0.51294\teval-mlogloss:0.65282\n",
            "[230]\ttrain-mlogloss:0.50983\teval-mlogloss:0.65318\n",
            "[236]\ttrain-mlogloss:0.50767\teval-mlogloss:0.65350\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        both       0.65      0.68      0.67       894\n",
            "       cause       0.59      0.12      0.20       436\n",
            "     emotion       0.60      0.57      0.59       750\n",
            "     neither       0.66      0.96      0.78       797\n",
            "\n",
            "    accuracy                           0.64      2877\n",
            "   macro avg       0.63      0.58      0.56      2877\n",
            "weighted avg       0.63      0.64      0.61      2877\n",
            "\n",
            "✅ Saved: annotated_output3.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np  \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "\n",
        "df = pd.read_csv(\"processed_train.csv\")\n",
        "\n",
        "def safe_eval(x):\n",
        "    try:\n",
        "        return ast.literal_eval(x)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "df['expanded emotion cause evidence'] = df['expanded emotion cause evidence'].apply(safe_eval)\n",
        "df['expanded emotion cause span'] = df['expanded emotion cause span'].apply(safe_eval)\n",
        "\n",
        "cause_clauses = set()\n",
        "for _, row in df.iterrows():\n",
        "    for cid in row['expanded emotion cause evidence'] + row['expanded emotion cause span']:\n",
        "        cause_clauses.add((row['conv_id'], cid))\n",
        "\n",
        "def get_annotation(row):\n",
        "    is_emotion = row['emotion'] != 'neutral' and row['emotion'] != ''\n",
        "    is_cause = (row['conv_id'], row['clause_number']) in cause_clauses\n",
        "    if is_emotion and is_cause:\n",
        "        return 'both'\n",
        "    elif is_emotion:\n",
        "        return 'emotion'\n",
        "    elif is_cause:\n",
        "        return 'cause'\n",
        "    else:\n",
        "        return 'neither'\n",
        "\n",
        "df['annotation'] = df.apply(get_annotation, axis=1)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
        "X_text = tfidf.fit_transform(df['clause'])\n",
        "\n",
        "df['clause_len'] = df['clause'].apply(lambda x: len(x.split()))\n",
        "df['is_emotion_present'] = df['emotion'].apply(lambda x: int(x != '' and x != 'neutral'))\n",
        "\n",
        "le_speaker = LabelEncoder()\n",
        "le_emotion = LabelEncoder()\n",
        "df['speaker_enc'] = le_speaker.fit_transform(df['speaker'])\n",
        "df['emotion_enc'] = le_emotion.fit_transform(df['emotion'])\n",
        "\n",
        "meta_features = df[['clause_len', 'turn', 'speaker_enc', 'emotion_enc', 'is_emotion_present']]\n",
        "scaler = StandardScaler()\n",
        "X_meta = scaler.fit_transform(meta_features)\n",
        "\n",
        "X_combined = hstack([X_text, X_meta])\n",
        "\n",
        "le_target = LabelEncoder()\n",
        "y = le_target.fit_transform(df['annotation'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_combined, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': len(le_target.classes_),\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.85,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'scale_pos_weight': 1.5,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "bst = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=500,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=20,\n",
        "    verbose_eval=10\n",
        ")\n",
        "\n",
        "y_pred_prob = bst.predict(dtest)\n",
        "y_pred = [np.argmax(prob) for prob in y_pred_prob]  # Use np.argmax after importing numpy\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=le_target.classes_))\n",
        "\n",
        "df['annotation'] = le_target.inverse_transform(bst.predict(xgb.DMatrix(X_combined)).argmax(axis=1))\n",
        "df.to_csv(\"annotated_output3.csv\", index=False)\n",
        "print(\"✅ Saved: annotated_output3.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY4aLKsqz1SL",
        "outputId": "4610adc6-62a7-440d-e3e2-c8725a8494b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:01:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-mlogloss:1.35058\teval-mlogloss:1.35436\n",
            "[10]\ttrain-mlogloss:1.06342\teval-mlogloss:1.10588\n",
            "[20]\ttrain-mlogloss:0.88930\teval-mlogloss:0.95643\n",
            "[30]\ttrain-mlogloss:0.77784\teval-mlogloss:0.86629\n",
            "[40]\ttrain-mlogloss:0.70171\teval-mlogloss:0.80702\n",
            "[50]\ttrain-mlogloss:0.64775\teval-mlogloss:0.76735\n",
            "[60]\ttrain-mlogloss:0.60904\teval-mlogloss:0.73951\n",
            "[70]\ttrain-mlogloss:0.58045\teval-mlogloss:0.72176\n",
            "[80]\ttrain-mlogloss:0.55538\teval-mlogloss:0.70678\n",
            "[90]\ttrain-mlogloss:0.53553\teval-mlogloss:0.69629\n",
            "[100]\ttrain-mlogloss:0.51920\teval-mlogloss:0.68734\n",
            "[110]\ttrain-mlogloss:0.50533\teval-mlogloss:0.68271\n",
            "[120]\ttrain-mlogloss:0.49331\teval-mlogloss:0.67972\n",
            "[130]\ttrain-mlogloss:0.48324\teval-mlogloss:0.67689\n",
            "[140]\ttrain-mlogloss:0.47306\teval-mlogloss:0.67412\n",
            "[150]\ttrain-mlogloss:0.46481\teval-mlogloss:0.67331\n",
            "[160]\ttrain-mlogloss:0.45723\teval-mlogloss:0.67263\n",
            "[170]\ttrain-mlogloss:0.45017\teval-mlogloss:0.67271\n",
            "[180]\ttrain-mlogloss:0.44335\teval-mlogloss:0.67324\n",
            "[182]\ttrain-mlogloss:0.44215\teval-mlogloss:0.67311\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        both       0.66      0.68      0.67       222\n",
            "       cause       0.48      0.20      0.28       176\n",
            "     emotion       0.65      0.63      0.64       209\n",
            "     neither       0.63      0.86      0.73       277\n",
            "\n",
            "    accuracy                           0.63       884\n",
            "   macro avg       0.61      0.59      0.58       884\n",
            "weighted avg       0.61      0.63      0.60       884\n",
            "\n",
            "✅ Saved: annotated_output3_test.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np  \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import hstack\n",
        "import xgboost as xgb\n",
        "\n",
        "df = pd.read_csv(\"processed_test.csv\")\n",
        "\n",
        "def safe_eval(x):\n",
        "    try:\n",
        "        return ast.literal_eval(x)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "df['expanded emotion cause evidence'] = df['expanded emotion cause evidence'].apply(safe_eval)\n",
        "df['expanded emotion cause span'] = df['expanded emotion cause span'].apply(safe_eval)\n",
        "\n",
        "cause_clauses = set()\n",
        "for _, row in df.iterrows():\n",
        "    for cid in row['expanded emotion cause evidence'] + row['expanded emotion cause span']:\n",
        "        cause_clauses.add((row['conv_id'], cid))\n",
        "\n",
        "def get_annotation(row):\n",
        "    is_emotion = row['emotion'] != 'neutral' and row['emotion'] != ''\n",
        "    is_cause = (row['conv_id'], row['clause_number']) in cause_clauses\n",
        "    if is_emotion and is_cause:\n",
        "        return 'both'\n",
        "    elif is_emotion:\n",
        "        return 'emotion'\n",
        "    elif is_cause:\n",
        "        return 'cause'\n",
        "    else:\n",
        "        return 'neither'\n",
        "\n",
        "df['annotation'] = df.apply(get_annotation, axis=1)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
        "X_text = tfidf.fit_transform(df['clause'])\n",
        "\n",
        "df['clause_len'] = df['clause'].apply(lambda x: len(x.split()))\n",
        "df['is_emotion_present'] = df['emotion'].apply(lambda x: int(x != '' and x != 'neutral'))\n",
        "\n",
        "le_speaker = LabelEncoder()\n",
        "le_emotion = LabelEncoder()\n",
        "df['speaker_enc'] = le_speaker.fit_transform(df['speaker'])\n",
        "df['emotion_enc'] = le_emotion.fit_transform(df['emotion'])\n",
        "\n",
        "meta_features = df[['clause_len', 'turn', 'speaker_enc', 'emotion_enc', 'is_emotion_present']]\n",
        "scaler = StandardScaler()\n",
        "X_meta = scaler.fit_transform(meta_features)\n",
        "\n",
        "X_combined = hstack([X_text, X_meta])\n",
        "\n",
        "le_target = LabelEncoder()\n",
        "y = le_target.fit_transform(df['annotation'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_combined, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': len(le_target.classes_),\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.05,\n",
        "    'subsample': 0.85,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'scale_pos_weight': 1.5,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "bst = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=500,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=20,\n",
        "    verbose_eval=10\n",
        ")\n",
        "\n",
        "y_pred_prob = bst.predict(dtest)\n",
        "y_pred = [np.argmax(prob) for prob in y_pred_prob]  # Use np.argmax after importing numpy\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=le_target.classes_))\n",
        "\n",
        "df['annotation'] = le_target.inverse_transform(bst.predict(xgb.DMatrix(X_combined)).argmax(axis=1))\n",
        "df.to_csv(\"annotated_output3_test.csv\", index=False)\n",
        "print(\"✅ Saved: annotated_output3_test.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
