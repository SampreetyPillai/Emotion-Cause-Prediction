{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB9IIamMBXPG",
        "outputId": "9cbbc53d-d4a1-4408-95e8-d2a725e7b69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.2)\n",
            "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.3.2)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib scikit-learn networkx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj8P5t7xDP7r",
        "outputId": "e6651783-ff06-4410-b315-f57344af3d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.1.2+pt20cpu)\n",
            "Requirement already satisfied: torch-sparse in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.6.18+pt20cpu)\n",
            "Requirement already satisfied: torch-cluster in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.6.3+pt20cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.2.2+pt20cpu)\n",
            "Requirement already satisfied: torch-geometric in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.6.1)\n",
            "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: pyparsing in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric dependencies for CPU in Colab\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOoQulLQLjFS",
        "outputId": "b9282c2c-23f3-4f48-94a0-e6ab7a3bc265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: Index(['id', 'clause', 'speaker', 'emotion_type', 'detected_emotion',\n",
            "       'embedding'],\n",
            "      dtype='object')\n",
            "            id                                         clause speaker  \\\n",
            "0  tr_4466_1_1         Hey , you wanna see a movie tomorrow ?       A   \n",
            "1  tr_4466_2_1                      Sounds like a good plan .       B   \n",
            "2  tr_4466_2_2                      What do you want to see ?       B   \n",
            "3  tr_4466_3_1                     How about Legally Blonde .       A   \n",
            "4  tr_4466_4_1  Ah , my girlfriend wanted to see that movie .       B   \n",
            "\n",
            "  emotion_type detected_emotion  \\\n",
            "0         both        happiness   \n",
            "1         both        happiness   \n",
            "2         both        happiness   \n",
            "3        cause          neutral   \n",
            "4        cause          neutral   \n",
            "\n",
            "                                           embedding  \n",
            "0  -0.08010987192392349,-0.031882286071777344,0.0...  \n",
            "1  -0.02023392915725708,0.0656646192073822,0.0207...  \n",
            "2  -0.015728836879134178,-0.020934388041496277,-0...  \n",
            "3  -0.00394107960164547,-0.10790738463401794,0.01...  \n",
            "4  -0.04076557978987694,-0.007892266847193241,-0....  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"node_embeddings1.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path, delimiter=',', engine='python', on_bad_lines='skip')\n",
        "except Exception as e:\n",
        "    print(f\"Error reading CSV: {e}\")\n",
        "    raise\n",
        "\n",
        "# Strip and inspect\n",
        "df.columns = df.columns.str.strip()\n",
        "print(\"Columns:\", df.columns)\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddDNqCh8oK8h",
        "outputId": "602c2464-15a4-49d4-ac1f-21017d80806d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['id', 'clause', 'speaker', 'emotion_type', 'detected_emotion', 'embedding']\n"
          ]
        }
      ],
      "source": [
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IBc0X4rZLloX"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Only do this once before graph construction\n",
        "df['embedding'] = df['embedding'].apply(lambda x: np.array([float(i) for i in x.split(',')]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vcv9NvgMnfH",
        "outputId": "b2dce21b-99e3-4309-f3f5-656b22aaf4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              id                                            clause speaker  \\\n",
            "0    tr_4466_1_1            Hey , you wanna see a movie tomorrow ?       A   \n",
            "1    tr_4466_2_1                         Sounds like a good plan .       B   \n",
            "2    tr_4466_2_2                         What do you want to see ?       B   \n",
            "3    tr_4466_3_1                        How about Legally Blonde .       A   \n",
            "4    tr_4466_4_1     Ah , my girlfriend wanted to see that movie .       B   \n",
            "..           ...                                               ...     ...   \n",
            "995  tr_1086_2_1               Yes , there is a lake in the park .       B   \n",
            "996  tr_1086_2_2                            It is very beautiful .       B   \n",
            "997  tr_1086_3_1                                  That ' s great .       A   \n",
            "998  tr_1086_3_2  We can go boating on the lake in the afternoon .       A   \n",
            "999  tr_1086_4_1                              It ' s a good idea .       B   \n",
            "\n",
            "    emotion_type detected_emotion  \\\n",
            "0           both        happiness   \n",
            "1           both        happiness   \n",
            "2           both        happiness   \n",
            "3          cause          neutral   \n",
            "4          cause          neutral   \n",
            "..           ...              ...   \n",
            "995      emotion        happiness   \n",
            "996         both        happiness   \n",
            "997         both        happiness   \n",
            "998      emotion        happiness   \n",
            "999         both        happiness   \n",
            "\n",
            "                                             embedding  \n",
            "0    [-0.08010987192392349, -0.031882286071777344, ...  \n",
            "1    [-0.02023392915725708, 0.0656646192073822, 0.0...  \n",
            "2    [-0.015728836879134178, -0.020934388041496277,...  \n",
            "3    [-0.00394107960164547, -0.10790738463401794, 0...  \n",
            "4    [-0.04076557978987694, -0.007892266847193241, ...  \n",
            "..                                                 ...  \n",
            "995  [0.018474120646715164, 0.02347749099135399, 0....  \n",
            "996  [0.014307722449302673, 0.07288335263729095, 0....  \n",
            "997  [-0.04191998019814491, -0.028463924303650856, ...  \n",
            "998  [-0.0026291648391634226, 0.050449397414922714,...  \n",
            "999  [-0.06402364373207092, 0.028639862313866615, -...  \n",
            "\n",
            "[1000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "df = df.iloc[:1000]\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.7557, Accuracy: 0.0016\n",
            "Epoch 2/10, Loss: 0.7464, Accuracy: 0.0016\n",
            "Epoch 3/10, Loss: 0.7371, Accuracy: 0.0016\n",
            "Epoch 4/10, Loss: 0.7273, Accuracy: 0.0016\n",
            "Epoch 5/10, Loss: 0.7167, Accuracy: 0.0096\n",
            "Epoch 6/10, Loss: 0.7049, Accuracy: 0.1531\n",
            "Epoch 7/10, Loss: 0.6914, Accuracy: 0.5541\n",
            "Epoch 8/10, Loss: 0.6759, Accuracy: 0.8641\n",
            "Epoch 9/10, Loss: 0.6579, Accuracy: 0.9669\n",
            "Epoch 10/10, Loss: 0.6374, Accuracy: 0.9909\n"
          ]
        }
      ],
      "source": [
        "embeddings = np.stack(df['embedding'].values)\n",
        "clause_ids = df['id'].tolist()\n",
        "id_to_index = {cid: idx for idx, cid in enumerate(clause_ids)}  # Maps clause ID to index\n",
        "\n",
        "# ------------------------\n",
        "# 2. Create Graph Edges Based on Cosine Similarity\n",
        "# ------------------------\n",
        "cos_sim = cosine_similarity(embeddings)\n",
        "threshold = 0.7\n",
        "edge_index = [[], []]\n",
        "\n",
        "for i in range(len(df)):\n",
        "    for j in range(len(df)):\n",
        "        if i != j and cos_sim[i][j] > threshold:\n",
        "            edge_index[0].append(i)\n",
        "            edge_index[1].append(j)\n",
        "\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "\n",
        "# ------------------------\n",
        "# 3. Load Emotion-Cause Pairs and Construct Label Matrix\n",
        "# ------------------------\n",
        "pair_df = pd.read_csv(\"emotion_cause_pairs.csv\")\n",
        "\n",
        "label_matrix = np.zeros((len(df), len(df)), dtype=np.float32)\n",
        "\n",
        "for _, row in pair_df.iterrows():\n",
        "    cause_id = row['cause_id']\n",
        "    emotion_id = row['emotion_id']\n",
        "    \n",
        "    if cause_id in id_to_index and emotion_id in id_to_index:\n",
        "        i = id_to_index[cause_id]\n",
        "        j = id_to_index[emotion_id]\n",
        "        label_matrix[i][j] = 1.0  # Binary label for valid emotion-cause pair\n",
        "\n",
        "label_matrix_tensor = torch.tensor(label_matrix)\n",
        "\n",
        "# ------------------------\n",
        "# 4. Graph Data Object\n",
        "# ------------------------\n",
        "x = torch.tensor(embeddings, dtype=torch.float32)\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# ------------------------\n",
        "# 5. Define DyGCN Model\n",
        "# ------------------------\n",
        "class DyGCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, pair_hidden=32):\n",
        "        super().__init__()\n",
        "        self.gcn = GCNConv(in_channels, hidden_channels)\n",
        "        self.pair_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_channels * 4, pair_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(pair_hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        h = self.gcn(data.x, data.edge_index)\n",
        "        num_nodes = h.size(0)\n",
        "\n",
        "        pair_vectors = []\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                hi = h[i]\n",
        "                hj = h[j]\n",
        "                pair_feat = torch.cat([hi, hj, hi * hj, hi - hj], dim=-1)\n",
        "                pair_vectors.append(pair_feat)\n",
        "\n",
        "        pair_vectors = torch.stack(pair_vectors)\n",
        "        scores = self.pair_mlp(pair_vectors).squeeze()\n",
        "        return scores.view(num_nodes, num_nodes)\n",
        "\n",
        "# ------------------------\n",
        "# 6. Training Setup\n",
        "# ------------------------\n",
        "def compute_loss(preds, labels):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    return criterion(preds.view(-1), labels.view(-1))\n",
        "\n",
        "model = DyGCN(in_channels=x.size(1), hidden_channels=128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ------------------------\n",
        "# 8. Define Accuracy Calculation\n",
        "# ------------------------\n",
        "def calculate_accuracy(preds, labels, threshold=0.5):\n",
        "    # Apply threshold to predictions (0 or 1)\n",
        "    preds = (torch.sigmoid(preds) > threshold).float()\n",
        "    correct = (preds == labels).sum().item()\n",
        "    total = labels.numel()  # Total number of labels\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# ------------------------\n",
        "# 9. Training Loop with Accuracy\n",
        "# ------------------------\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(data)  # shape: (N, N)\n",
        "    loss = compute_loss(output, label_matrix_tensor)\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = calculate_accuracy(output, label_matrix_tensor)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss and accuracy every epoch\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as dygcn_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Save the model after training\n",
        "torch.save(model.state_dict(), 'dygcn_model.pth')\n",
        "print(\"Model saved as dygcn_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        cause_id   emotion_id                  cause_sentence  \\\n",
            "0     tr_924_6_2   tr_924_6_2  The water was too cold , huh ?   \n",
            "1     tr_924_6_2   tr_924_6_3  The water was too cold , huh ?   \n",
            "2     tr_924_6_2   tr_924_6_4  The water was too cold , huh ?   \n",
            "3     tr_924_6_2   tr_924_6_5  The water was too cold , huh ?   \n",
            "4     tr_924_6_2   tr_924_6_6  The water was too cold , huh ?   \n",
            "..           ...          ...                             ...   \n",
            "620  tr_1086_4_1  tr_1086_2_1            It ' s a good idea .   \n",
            "621  tr_1086_4_1  tr_1086_2_2            It ' s a good idea .   \n",
            "622  tr_1086_4_1  tr_1086_3_1            It ' s a good idea .   \n",
            "623  tr_1086_4_1  tr_1086_3_2            It ' s a good idea .   \n",
            "624  tr_1086_4_1  tr_1086_4_1            It ' s a good idea .   \n",
            "\n",
            "                                      emotion_sentence  \n",
            "0                       The water was too cold , huh ?  \n",
            "1                           I ' ll tell you a secret .  \n",
            "2     Do you see that small pool of water over there ?  \n",
            "3                         It ' ll be warmer in there .  \n",
            "4    Go see if you can find some seashells or catch...  \n",
            "..                                                 ...  \n",
            "620                Yes , there is a lake in the park .  \n",
            "621                             It is very beautiful .  \n",
            "622                                   That ' s great .  \n",
            "623   We can go boating on the lake in the afternoon .  \n",
            "624                               It ' s a good idea .  \n",
            "\n",
            "[625 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn as nn\n",
        "\n",
        "# Assuming model and other variables are already set up and trained\n",
        "\n",
        "# ------------------------\n",
        "# Use the last 25 rows from the dataframe\n",
        "# ------------------------\n",
        "\n",
        "df_last_25 = df.tail(25)\n",
        "\n",
        "# Convert embeddings to numpy array for the last 25 rows\n",
        "embeddings = np.stack(df_last_25['embedding'].values)\n",
        "clause_ids = df_last_25['id'].tolist()\n",
        "id_to_index = {cid: idx for idx, cid in enumerate(clause_ids)}\n",
        "\n",
        "# Create cosine similarity matrix for the last 25 embeddings\n",
        "cos_sim = cosine_similarity(embeddings)\n",
        "threshold = 0.7\n",
        "edge_index = [[], []]\n",
        "\n",
        "for i in range(len(df_last_25)):\n",
        "    for j in range(len(df_last_25)):\n",
        "        if i != j and cos_sim[i][j] > threshold:\n",
        "            edge_index[0].append(i)\n",
        "            edge_index[1].append(j)\n",
        "\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "\n",
        "# Prepare the graph data object\n",
        "x = torch.tensor(embeddings, dtype=torch.float32)\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# ------------------------\n",
        "# Load the trained DyGCN model\n",
        "# ------------------------\n",
        "\n",
        "model = DyGCN(in_channels=x.size(1), hidden_channels=128)\n",
        "model.load_state_dict(torch.load(\"dygcn_model.pth\"))\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# ------------------------\n",
        "# Make predictions\n",
        "# ------------------------\n",
        "\n",
        "# Get the output from the model (predictions)\n",
        "with torch.no_grad():\n",
        "    output = model(data)\n",
        "\n",
        "# Apply sigmoid to get probabilities\n",
        "predictions = torch.sigmoid(output)\n",
        "\n",
        "# Now, make predictions on emotion-cause pairs\n",
        "# Apply a lower threshold to classify pairs\n",
        "threshold = 0.3  # Lower the threshold to capture more pairs\n",
        "predictions = (predictions > threshold).float()\n",
        "\n",
        "# Convert predictions into a DataFrame or list of predicted pairs\n",
        "predicted_pairs = []\n",
        "\n",
        "# Iterate over the prediction matrix\n",
        "for i in range(predictions.size(0)):\n",
        "    for j in range(predictions.size(1)):\n",
        "        if predictions[i, j] == 1:\n",
        "            cause_id = clause_ids[i]\n",
        "            emotion_id = clause_ids[j]\n",
        "            cause_sentence = df_last_25.iloc[i]['clause']\n",
        "            emotion_sentence = df_last_25.iloc[j]['clause']\n",
        "            predicted_pairs.append((cause_id, emotion_id, cause_sentence, emotion_sentence))\n",
        "\n",
        "# Create a DataFrame for the predicted pairs with sentences\n",
        "predicted_pairs_df = pd.DataFrame(predicted_pairs, columns=[\"cause_id\", \"emotion_id\", \"cause_sentence\", \"emotion_sentence\"])\n",
        "\n",
        "# Show the predicted pairs\n",
        "print(predicted_pairs_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted emotion-cause pairs saved to 'predicted_emotion_cause_pairs.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Save the predicted pairs with sentences to a CSV file\n",
        "predicted_pairs_df.to_csv(\"predicted_emotion_cause_pairs.csv\", index=False)\n",
        "\n",
        "# Print a message confirming the file has been saved\n",
        "print(\"Predicted emotion-cause pairs saved to 'predicted_emotion_cause_pairs.csv'.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
